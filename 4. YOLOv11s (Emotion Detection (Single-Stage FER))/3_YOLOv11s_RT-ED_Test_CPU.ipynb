{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for YOLOv11 Emotion Detection Model (CPU Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Verify dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"D:\\College\\Semester 8\\Skripsi\\Program (Google Colab)\\Programs\\Datasets\\YOLOv11s_ED\\test-4\"\n",
    "test_img_dir = os.path.join(dataset_path, \"train\", \"images\")\n",
    "test_label_dir = os.path.join(dataset_path, \"train\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if test directories exist\n",
    "if not os.path.exists(test_img_dir) or not os.path.exists(test_label_dir):\n",
    "    raise FileNotFoundError(f\"Test directories not found at {test_img_dir} or {test_label_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Update data.yaml with absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "with open(data_yaml_path, \"r\") as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "# Use absolute paths for the test set (use train folder as the test set)\n",
    "data_yaml[\"train\"] = os.path.abspath(os.path.join(dataset_path, \"train/images\"))\n",
    "data_yaml[\"val\"] = \"\"  # No validation set\n",
    "data_yaml[\"test\"] = os.path.abspath(os.path.join(dataset_path, \"train/images\"))  # Use all images for testing\n",
    "data_yaml[\"nc\"] = 7\n",
    "data_yaml[\"names\"] = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    yaml.safe_dump(data_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify paths exist\n",
    "if not os.path.exists(data_yaml[\"test\"]):\n",
    "    raise FileNotFoundError(f\"Test image directory not found: {data_yaml['test']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load fine-tuned YOLOv11 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"D:\\College\\Semester 8\\Skripsi\\Program (Google Colab)\\Programs\\Models\\YOLOv11s_Emotion_Detection.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\miniconda3\\envs\\yolo11ed_cpu\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Batch evaluation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168  Python-3.11.13 torch-2.7.1+cpu CPU (AMD Ryzen 5 7535HS with Radeon Graphics)\n",
      "YOLO11s summary (fused): 100 layers, 9,415,509 parameters, 0 gradients, 21.3 GFLOPs\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\ASUS\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 6.60MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 21.66.8 MB/s, size: 204.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\College\\Semester 8\\Skripsi\\Program (Google Colab)\\Programs\\Datasets\\YOLOv11s_ED\\test-4\\train\\labels... 536 images, 0 backgrounds, 0 corrupt: 100%|██████████| 536/536 [00:01<00:00, 378.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\College\\Semester 8\\Skripsi\\Program (Google Colab)\\Programs\\Datasets\\YOLOv11s_ED\\test-4\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\ASUS\\miniconda3\\envs\\yolo11ed_cpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:42<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        536      19056      0.206      0.215       0.16      0.111\n",
      "                 Angry        523       1859      0.201      0.114      0.121     0.0819\n",
      "               Disgust        354        701      0.182      0.173      0.117     0.0892\n",
      "                  Fear        188        292    0.00932     0.0274    0.00499    0.00146\n",
      "                 Happy        536       2342      0.228      0.418      0.251      0.177\n",
      "               Neutral        536      10305      0.546      0.607      0.462      0.305\n",
      "                   Sad        514       2310      0.158     0.0281     0.0815      0.064\n",
      "              Surprise        494       1247      0.117      0.134     0.0853     0.0565\n",
      "Speed: 0.5ms preprocess, 65.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      "Test Metrics:\n",
      "mAP@50: 0.1603\n",
      "mAP@50:95: 0.1106\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation (mAP) and inference on the test set\n",
    "val_results = model.val(\n",
    "    data=data_yaml_path,\n",
    "    batch=32,  # Batch size (CPU can handle similar batch size)\n",
    "    conf=0.25,  # Confidence threshold for inference\n",
    "    save=True,  # Save inference results\n",
    "    split=\"test\",  # Use test set (all 536 images)\n",
    "    device=\"cpu\"  # Force CPU usage\n",
    ")\n",
    "\n",
    "# Extract and print mAP metrics\n",
    "print(\"Test Metrics:\")\n",
    "print(f\"mAP@50: {val_results.box.map50:.4f}\")\n",
    "print(f\"mAP@50:95: {val_results.box.map:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speed Metrics (per image):\n",
      "Preprocess: 0.5ms\n",
      "Inference: 65.3ms\n",
      "Postprocess: 0.4ms\n",
      "Total (Latency): 66.2ms\n",
      "FPS: 15.11\n",
      "\n",
      "Per Face Metrics:\n",
      "Average faces per image: 35.55\n",
      "Inference time per face: 1.836ms\n",
      "Latency per face: 1.862ms\n",
      "FPS per face: 544.80\n"
     ]
    }
   ],
   "source": [
    "# Extract speed metrics\n",
    "preprocess_time = val_results.speed['preprocess']  # ms per image\n",
    "inference_time = val_results.speed['inference']    # ms per image\n",
    "postprocess_time = val_results.speed['postprocess']  # ms per image\n",
    "total_time_per_image = preprocess_time + inference_time + postprocess_time  # ms\n",
    "\n",
    "# Calculate FPS (per image)\n",
    "fps = 1000 / total_time_per_image if total_time_per_image > 0 else 0\n",
    "\n",
    "# Calculate inference time per face, latency per face, and FPS per face\n",
    "num_images = 536  # Total images in dataset\n",
    "num_instances = sum(val_results.nt_per_class)  # Total instances\n",
    "avg_faces_per_image = num_instances / num_images if num_images > 0 else 0\n",
    "inference_time_per_face = inference_time / avg_faces_per_image if avg_faces_per_image > 0 else 0\n",
    "latency_per_face = total_time_per_image / avg_faces_per_image if avg_faces_per_image > 0 else 0\n",
    "fps_per_face = 1000 / inference_time_per_face if inference_time_per_face > 0 else 0\n",
    "\n",
    "# Print speed metrics, FPS, and per-face metrics\n",
    "print(\"\\nSpeed Metrics (per image):\")\n",
    "print(f\"Preprocess: {preprocess_time:.1f}ms\")\n",
    "print(f\"Inference: {inference_time:.1f}ms\")\n",
    "print(f\"Postprocess: {postprocess_time:.1f}ms\")\n",
    "print(f\"Total (Latency): {total_time_per_image:.1f}ms\")\n",
    "print(f\"FPS: {fps:.2f}\")\n",
    "print(f\"\\nPer Face Metrics:\")\n",
    "print(f\"Average faces per image: {avg_faces_per_image:.2f}\")\n",
    "print(f\"Inference time per face: {inference_time_per_face:.3f}ms\")\n",
    "print(f\"Latency per face: {latency_per_face:.3f}ms\")\n",
    "print(f\"FPS per face: {fps_per_face:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_path = r\"D:\\College\\Semester 8\\Skripsi\\Program (Google Colab)\\Programs\\Models\\YOLOv11s_RT-FER_Test_CPU\"\n",
    "os.makedirs(results_save_path, exist_ok=True)  # Ensure directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to D:\\College\\Semester 8\\Skripsi\\Program (Google Colab)\\Programs\\Models\\YOLOv11s_RT-FER_Test_CPU\\test_metrics.txt\n"
     ]
    }
   ],
   "source": [
    "# Save metrics to local directory\n",
    "metrics_file = os.path.join(results_save_path, \"test_metrics.txt\")\n",
    "os.makedirs(os.path.dirname(metrics_file), exist_ok=True)  # Ensure parent directory exists\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    f.write(f\"Test Metrics:\\n\")\n",
    "    f.write(f\"mAP@50: {val_results.box.map50:.4f}\\n\")\n",
    "    f.write(f\"mAP@50:95: {val_results.box.map:.4f}\\n\")\n",
    "    f.write(f\"\\nSpeed Metrics (per image):\\n\")\n",
    "    f.write(f\"Preprocess: {preprocess_time:.1f}ms\\n\")\n",
    "    f.write(f\"Inference: {inference_time:.1f}ms\\n\")\n",
    "    f.write(f\"Postprocess: {postprocess_time:.1f}ms\\n\")\n",
    "    f.write(f\"Total (Latency): {total_time_per_image:.1f}ms\\n\")\n",
    "    f.write(f\"FPS: {fps:.2f}\\n\")\n",
    "    f.write(f\"\\nPer Face Metrics:\\n\")\n",
    "    f.write(f\"Average faces per image: {avg_faces_per_image:.2f}\\n\")\n",
    "    f.write(f\"Inference time per face: {inference_time_per_face:.3f}ms\\n\")\n",
    "    f.write(f\"Latency per face: {latency_per_face:.3f}ms\\n\")\n",
    "    f.write(f\"FPS per face: {fps_per_face:.2f}\\n\")\n",
    "print(f\"Metrics saved to {metrics_file}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolo11ed_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
